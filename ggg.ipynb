{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [20 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"c:\\Users\\dev\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"c:\\Users\\dev\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\dev\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\dev\\AppData\\Local\\Temp\\pip-build-env-4k284zeb\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 332, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=[])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\dev\\AppData\\Local\\Temp\\pip-build-env-4k284zeb\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 302, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\dev\\AppData\\Local\\Temp\\pip-build-env-4k284zeb\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 318, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 12, in <module>\n",
      "        File \"C:\\Users\\dev\\AppData\\Local\\Temp\\pip-build-env-4k284zeb\\overlay\\Lib\\site-packages\\torch\\__init__.py\", line 148, in <module>\n",
      "          raise err\n",
      "      OSError: [WinError 126] 吏\\x80\\xec젙\\xeb맂 紐⑤뱢\\xec쓣 李얠쓣 \\xec닔 \\xec뾾\\xec뒿\\xeb땲\\xeb떎. Error loading \"C:\\Users\\dev\\AppData\\Local\\Temp\\pip-build-env-4k284zeb\\overlay\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: openai in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.44.0)\n",
      "Requirement already satisfied: gradio in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.43.0)\n",
      "Requirement already satisfied: llama-index-core in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.11.7)\n",
      "Requirement already satisfied: llama-index-readers-file in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: llama-index-llms-ollama in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.1)\n",
      "Collecting vllm\n",
      "  Using cached vllm-0.6.0.tar.gz (1.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "pip install langchain openai gradio llama-index-core llama-index-readers-file llama-index-llms-ollama llama-index-embeddings-huggingface vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-core in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.11.7)\n",
      "Requirement already satisfied: llama-index-readers-file in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.1)\n",
      "Collecting llama-index-llms-ollama\n",
      "  Downloading llama_index_llms_ollama-0.3.1-py3-none-any.whl.metadata (668 bytes)\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl.metadata (718 bytes)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (2024.9.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\dev\\appdata\\roaming\\python\\python312\\site-packages (from llama-index-core) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-readers-file) (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-readers-file) (2.2.2)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-readers-file) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-readers-file) (0.0.26)\n",
      "Collecting ollama>=0.3.0 (from llama-index-llms-ollama)\n",
      "  Downloading ollama-0.3.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.24.6)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.9.11)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.16.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dev\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.1)\n",
      "Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Downloading minijinja-2.2.0-cp38-abi3-win_amd64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: click in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>3.8.1->llama-index-core) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>3.8.1->llama-index-core) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>3.8.1->llama-index-core) (2024.7.24)\n",
      "Requirement already satisfied: anyio in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx->llama-index-core) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx->llama-index-core) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx->llama-index-core) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx->llama-index-core) (3.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (2.2.2)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading torch-2.4.1-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\dev\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json->llama-index-core) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dev\\appdata\\roaming\\python\\python312\\site-packages (from pandas->llama-index-readers-file) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->llama-index-readers-file) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->llama-index-readers-file) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dev\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file) (1.16.0)\n",
      "Collecting sympy (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (74.1.2)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.5)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading llama_index_llms_ollama-0.3.1-py3-none-any.whl (4.5 kB)\n",
      "Downloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl (8.6 kB)\n",
      "Downloading ollama-0.3.2-py3-none-any.whl (10 kB)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "Downloading minijinja-2.2.0-cp38-abi3-win_amd64.whl (762 kB)\n",
      "   ---------------------------------------- 0.0/762.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 762.2/762.2 kB 6.4 MB/s eta 0:00:00\n",
      "Downloading torch-2.4.1-cp312-cp312-win_amd64.whl (199.4 MB)\n",
      "   ---------------------------------------- 0.0/199.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/199.4 MB 11.7 MB/s eta 0:00:17\n",
      "    --------------------------------------- 4.7/199.4 MB 11.9 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 7.1/199.4 MB 11.8 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 8.7/199.4 MB 10.5 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 11.0/199.4 MB 10.7 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 13.6/199.4 MB 11.0 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 16.0/199.4 MB 11.1 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 18.4/199.4 MB 11.1 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 21.0/199.4 MB 11.1 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 23.1/199.4 MB 11.1 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 24.9/199.4 MB 10.9 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 26.5/199.4 MB 10.7 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 28.8/199.4 MB 10.6 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 30.9/199.4 MB 10.6 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 32.5/199.4 MB 10.6 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 33.3/199.4 MB 9.9 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 35.7/199.4 MB 10.0 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 37.7/199.4 MB 10.1 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 39.8/199.4 MB 10.0 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 42.5/199.4 MB 10.1 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 44.8/199.4 MB 10.2 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 47.2/199.4 MB 10.2 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 49.5/199.4 MB 10.3 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 52.2/199.4 MB 10.3 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 53.5/199.4 MB 10.2 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 55.8/199.4 MB 10.2 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 58.5/199.4 MB 10.3 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 60.0/199.4 MB 10.2 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 61.3/199.4 MB 10.1 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 62.9/199.4 MB 10.0 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 64.0/199.4 MB 9.9 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 65.3/199.4 MB 9.7 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 66.8/199.4 MB 9.6 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 68.2/199.4 MB 9.6 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 69.7/199.4 MB 9.5 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 71.6/199.4 MB 9.4 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 72.9/199.4 MB 9.4 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 73.4/199.4 MB 9.4 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 75.0/199.4 MB 9.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 77.6/199.4 MB 9.3 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 80.2/199.4 MB 9.3 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 82.6/199.4 MB 9.4 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 85.2/199.4 MB 9.5 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 87.0/199.4 MB 9.5 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 89.1/199.4 MB 9.4 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 91.5/199.4 MB 9.5 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 94.1/199.4 MB 9.6 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 96.5/199.4 MB 9.6 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 99.1/199.4 MB 9.6 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 100.7/199.4 MB 9.7 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 103.0/199.4 MB 9.6 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 105.6/199.4 MB 9.7 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 107.7/199.4 MB 9.7 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 110.1/199.4 MB 9.7 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 112.5/199.4 MB 9.7 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 114.0/199.4 MB 9.7 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 116.1/199.4 MB 9.7 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 118.8/199.4 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 121.1/199.4 MB 9.8 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 123.5/199.4 MB 9.8 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 125.8/199.4 MB 9.8 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 128.2/199.4 MB 9.8 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 130.5/199.4 MB 9.9 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 132.4/199.4 MB 9.9 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 134.5/199.4 MB 9.9 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 136.6/199.4 MB 9.9 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 138.9/199.4 MB 9.9 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 141.0/199.4 MB 9.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 143.1/199.4 MB 9.9 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 145.2/199.4 MB 9.9 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 147.6/199.4 MB 9.9 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 149.7/199.4 MB 9.9 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 151.8/199.4 MB 9.9 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 153.6/199.4 MB 9.9 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 155.5/199.4 MB 9.9 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 157.8/199.4 MB 9.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 160.2/199.4 MB 9.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 162.8/199.4 MB 10.0 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 165.4/199.4 MB 10.0 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 167.8/199.4 MB 10.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 168.8/199.4 MB 10.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 170.9/199.4 MB 10.0 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 172.5/199.4 MB 9.9 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 173.8/199.4 MB 9.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 175.1/199.4 MB 9.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 176.9/199.4 MB 9.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 179.0/199.4 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 181.1/199.4 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 183.2/199.4 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 185.9/199.4 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 188.5/199.4 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 188.7/199.4 MB 9.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 190.8/199.4 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 192.9/199.4 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  195.6/199.4 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.2/199.4 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.4/199.4 MB 9.4 MB/s eta 0:00:00\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 2.6/9.5 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.2/9.5 MB 12.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.9/9.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 11.1 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.4/6.2 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.0/6.2 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 8.8 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, safetensors, minijinja, torch, tokenizers, ollama, transformers, llama-index-llms-ollama, sentence-transformers, llama-index-embeddings-huggingface\n",
      "Successfully installed llama-index-embeddings-huggingface-0.3.1 llama-index-llms-ollama-0.3.1 minijinja-2.2.0 mpmath-1.3.0 ollama-0.3.2 safetensors-0.4.5 sentence-transformers-3.0.1 sympy-1.13.2 tokenizers-0.19.1 torch-2.4.1 transformers-4.44.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index-core llama-index-readers-file llama-index-llms-ollama llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-openai in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting llama-index-llms-langchain\n",
      "  Downloading llama_index_llms_langchain-0.4.1-py3-none-any.whl.metadata (629 bytes)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-llms-openai) (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.7 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-llms-openai) (0.11.7)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-llms-openai) (1.44.0)\n",
      "Requirement already satisfied: langchain>=0.1.3 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-llms-langchain) (0.2.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain>=0.1.3->llama-index-llms-langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain>=0.1.3->llama-index-llms-langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain>=0.1.3->llama-index-llms-langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain>=0.1.3->llama-index-llms-langchain) (0.2.38)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain>=0.1.3->llama-index-llms-langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain>=0.1.3->llama-index-llms-langchain) (0.1.114)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain>=0.1.3->llama-index-llms-langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain>=0.1.3->llama-index-llms-langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain>=0.1.3->llama-index-llms-langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain>=0.1.3->llama-index-llms-langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.9.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\dev\\appdata\\roaming\\python\\python312\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.9.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (10.4.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.3->llama-index-llms-langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.3->llama-index-llms-langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.3->llama-index-llms-langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.3->llama-index-llms-langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.3->llama-index-llms-langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.3->llama-index-llms-langchain) (1.9.11)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.8)\n",
      "Requirement already satisfied: certifi in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain>=0.1.3->llama-index-llms-langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dev\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain>=0.1.3->llama-index-llms-langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain>=0.1.3->llama-index-llms-langchain) (3.10.7)\n",
      "Requirement already satisfied: click in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.7.24)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.1.3->llama-index-llms-langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.1.3->llama-index-llms-langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain>=0.1.3->llama-index-llms-langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain>=0.1.3->llama-index-llms-langchain) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.1.3->llama-index-llms-langchain) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\dev\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.22.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dev\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain>=0.1.3->llama-index-llms-langchain) (3.0.0)\n",
      "Downloading llama_index_llms_langchain-0.4.1-py3-none-any.whl (4.9 kB)\n",
      "Installing collected packages: llama-index-llms-langchain\n",
      "Successfully installed llama-index-llms-langchain-0.4.1\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index-llms-openai llama-index-llms-langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dev\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatAnyscale, ChatOpenAI\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, GPTListIndex, GPTSimpleKeywordTableIndex, PromptHelper, StorageContext, load_index_from_storage\n",
    "from llama_index.llms.langchain import LangChainLLM\n",
    "from langchain import OpenAI\n",
    "import gradio as gr\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dev\\AppData\\Local\\Temp\\ipykernel_13136\\2122851681.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  llm = LangChainLLM(ChatOpenAI())\n"
     ]
    }
   ],
   "source": [
    "llm = LangChainLLM(ChatOpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디렉터리 'docs'가 이미 존재합니다.\n"
     ]
    }
   ],
   "source": [
    "# 'docs' 디렉터리가 없으면 생성합니다.\n",
    "if not os.path.exists(\"docs\"):\n",
    "    os.makedirs(\"docs\")\n",
    "    print(\"디렉터리 'docs'가 생성되었습니다. 이 폴더에 문서를 추가하세요.\")\n",
    "else:\n",
    "    print((\"디렉터리 'docs'가 이미 존재합니다.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_index(directory_path):\n",
    "    max_input_size = 4096\n",
    "    num_outputs = 512\n",
    "    chunk_overlap_ratio = 0.2  # Changed this to a float ratio\n",
    "    chunk_size_limit = 600\n",
    "\n",
    "    # PromptHelper to handle chunking\n",
    "    prompt_helper = PromptHelper(max_input_size, num_outputs, chunk_overlap_ratio, chunk_size_limit=chunk_size_limit)\n",
    "\n",
    "    # Initialize the LangChain LLM with OpenAI's chat model\n",
    "    llm = LangChainLLM(llm=ChatOpenAI(temperature=0.7, model_name=\"gpt-4o\", max_tokens=num_outputs))\n",
    "\n",
    "    # Load documents using SimpleDirectoryReader\n",
    "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
    "\n",
    "    # Create VectorStoreIndex for document search and response generation\n",
    "    index = VectorStoreIndex.from_documents(documents, llm=llm, prompt_helper=prompt_helper)\n",
    "\n",
    "    # Save the index to disk\n",
    "    index.storage_context.persist(persist_dir='index.json')\n",
    "\n",
    "    return index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(input_text):\n",
    "    # 저장된 인덱스를 로드\n",
    "    storage_context = StorageContext.from_defaults(persist_dir='index.json')\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    \n",
    "    # 쿼리할 때 사용되는 쿼리 엔진을 생성합니다.\n",
    "    query_engine = index.as_query_engine()\n",
    "\n",
    "    # 입력된 텍스트에 대해 쿼리를 실행하고 응답을 얻습니다.\n",
    "    response = query_engine.query(input_text+\"+한국어로 대답을 생성해줘.\")\n",
    "    \n",
    "    return str(response)  # 응답을 문자열로 변환하여 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x162b28daa20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the index from a document directory (e.g., \"docs\")\n",
    "index = construct_index(\"docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 31):\n",
    "    # 사용자 입력을 받아서 챗봇과 상호작용하는 방식으로 변경\n",
    "    if __name__ == \"__main__\":\n",
    "        user_input = \"\"\"\n",
    "            아래 정보에 기반하여 서로 다른 문제를 출제해줘.\n",
    "\n",
    "            ## 문제의 형식\n",
    "            1. 문제는 발문과 선지로 이루어져 있다.\n",
    "            2. 선지는 반드시 4개이고 중복 정답은 없다.\n",
    "            3. 모든 문제는 '모든 답이 맞다.' 혹은 '모든 답이 틀리다.', '정답이 없다.'라는 선지를 가질 수 없다.\n",
    "            4. 각 선지에 발문의 내용과 크게 상충되거나, 극단적으로 보여지는 내용은 사용하지 않는다.\n",
    "            5. 위 네가지 형식을 반드시 준수하되, 숫자가 적은 형식이 우위를 가진다.\n",
    "\n",
    "\n",
    "            ## 문제 예시\n",
    "            헤어세팅에 있어서 웨이브의 형상에 따라 분류하는 것으로서 크레스트가 너무 약하게 되어 리지가 눈에 잘 띄지 않은 웨이브는?\n",
    "\n",
    "            1) 버티컬 웨이브    2) 새도우 웨이브    3) 내로우 웨이브    4) 와이드 웨이브\n",
    "            정답: 새도우 웨이브\n",
    "        \"\"\"\n",
    "        response = chatbot(user_input)\n",
    "        with open(\"output.txt\", \"a\", encoding=\"utf-8\") as file:\n",
    "            # 파일에 문자열 쓰기\n",
    "            file.write(str(i) + \". \" + response)\n",
    "            file.write(\"\\n\\n\")  # 줄바꿈 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT 챗봇을 시작합니다. '종료'라고 입력하면 종료됩니다.\n",
      "챗봇 응답: 1. 얼굴을 깨끗하게 하는 과정에서 사용되는 제품은? 1) 클렌징폼 2) 바디로션 3) 샴푸 4) 립밤\n",
      "2. 피부를 촉촉하고 부드럽게 하는 제품은? 1) 선크림 2) 클렌징워터 3) 스킨로션 4) 헤어젤\n",
      "3. 피부를 진정시키는 효과가 있는 제품은? 1) 세럼 2) 마스크시트 3) 토너 4) 아이크림\n",
      "4. 피부에 수분을 공급하는 제품은? 1) 섀도우 2) 파운데이션 3) 에센스 4) 립틴트\n",
      "5. 피부를 탄력있게 하는 제품은? 1) 립스틱 2) 블러셔 3) 크림 4) 세럼\n",
      "챗봇을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "# 사용자 입력을 받아서 챗봇과 상호작용하는 방식으로 변경\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"GPT 챗봇을 시작합니다. '종료'라고 입력하면 종료됩니다.\")\n",
    "    while True:\n",
    "        user_input = input(\"질문을 입력하세요: \")\n",
    "        if user_input.lower() == \"종료\":\n",
    "            print(\"챗봇을 종료합니다.\")\n",
    "            break\n",
    "        response = chatbot(user_input)\n",
    "        print(\"챗봇 응답:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gradio Interface for: chatbot\n",
       "-----------------------------\n",
       "inputs:\n",
       "|-<gradio.components.textbox.Textbox object at 0x00000162B389FAD0>\n",
       "outputs:\n",
       "|-<gradio.components.textbox.Textbox object at 0x00000162B389C2C0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio interface setup\n",
    "iface = gr.Interface(fn=chatbot,\n",
    "                     inputs=gr.Textbox(lines=7, label=\"Enter your text\"),\n",
    "                     outputs=\"text\",\n",
    "                     title=\"챗봇\")\n",
    "\n",
    "iface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://e585a383aa56deeed8.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e585a383aa56deeed8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch the Gradio interface\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7865\n"
     ]
    }
   ],
   "source": [
    "iface.close()   # 서버 종료"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
